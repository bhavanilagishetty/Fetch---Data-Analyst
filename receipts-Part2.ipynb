{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Try running with errors='ignore' as key '$oid' is not always present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001b[0m in \u001b[0;36m_recursive_extract\u001b[1;34m(data, path, seen_meta, level)\u001b[0m\n\u001b[0;32m    313\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                             \u001b[0mmeta_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pull_field\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001b[0m in \u001b[0;36m_pull_field\u001b[1;34m(js, spec)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '$oid'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6134a8667f39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Flatten the JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rewardsReceiptItemList'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'$oid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001b[0m in \u001b[0;36m_json_normalize\u001b[1;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[0;32m    325\u001b[0m                 \u001b[0mrecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0m_recursive_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001b[0m in \u001b[0;36m_recursive_extract\u001b[1;34m(data, path, seen_meta, level)\u001b[0m\n\u001b[0;32m    318\u001b[0m                             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                                 raise KeyError(\n\u001b[1;32m--> 320\u001b[1;33m                                     \u001b[1;34m\"Try running with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m                                     \u001b[1;34m\"errors='ignore' as key \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                                     \u001b[1;34mf\"{e} is not always present\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Try running with errors='ignore' as key '$oid' is not always present\""
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "\n",
    "# Read the JSON file\n",
    "with open('D:/Resume/FetchInterview/receipts.json - Copy/receipts.json') as f:\n",
    "    #data = json.load(f)\n",
    "    data = f.read()\n",
    "    data = data.split(\"}\\n\")\n",
    "    data = [d.strip() + \"}\" for d in data]\n",
    "    data = list(filter((\"}\").__ne__, data))\n",
    "    data = [json.loads(d) for d in data]\n",
    "\n",
    "    \n",
    "flattened_data = []\n",
    "\n",
    "for entry in data:\n",
    "\n",
    "    if 'rewardsReceiptItemList' in entry and entry['rewardsReceiptItemList']:\n",
    "        # Flatten the 'rewardsReceiptItemList' array and add other data\n",
    "        for item in entry['rewardsReceiptItemList']:\n",
    "            flat_item = entry.copy()\n",
    "            flat_item.update(item)\n",
    "            flattened_data.append(flat_item)\n",
    "            \n",
    "\n",
    "#data2 = data[['_id', 'rewardsReceiptItemList']]\n",
    "        \n",
    "# Flatten the JSON\n",
    "result = pd.json_normalize(data, 'rewardsReceiptItemList',['_id','$oid'])\n",
    "\n",
    "result\n",
    "# Convert to DataFrame\n",
    "#df = pd.DataFrame(flattened_data)\n",
    "\n",
    "\n",
    "\n",
    "# Remove the original 'rewardsReceiptItemList' column\n",
    "#df.drop(columns=['pointsAwardedDate.$date','bonusPointsEarned','bonusPointsEarnedReason','createDate.$date',\n",
    "#                 'dateScanned.$date','finishedDate.$date','modifyDate.$date','pointsEarned','purchaseDate.$date','purchasedItemCount',\n",
    "#                 'rewardsReceiptStatus','totalSpent','userId'], inplace=True)\n",
    "\n",
    "#df2[['_id']]\n",
    "#df\n",
    "\n",
    "# Write to CSV file\n",
    "#df.to_csv('D:/Resume/FetchInterview/receipts.json - Copy/output1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_oid(row):\n",
    "    return row['$oid']\n",
    "\n",
    "df['id_oid'] = df['_id'].apply(lambda x: get_id_oid(x))\n",
    "\n",
    "df.drop(columns=['_id'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(row):\n",
    "    if isinstance(row, dict) and '$date' in row:\n",
    "        return datetime.utcfromtimestamp(row['$date'] / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['createDate1'] = df['createDate'].apply(extract_date)\n",
    "df['dateScanned1'] = df['dateScanned'].apply(extract_date)\n",
    "df['finishedDate1'] = df['finishedDate'].apply(extract_date)\n",
    "df['modifyDate1'] = df['modifyDate'].apply(extract_date)\n",
    "df['pointsAwardedDate1'] = df['pointsAwardedDate'].apply(extract_date)\n",
    "df['purchaseDate1'] = df['purchaseDate'].apply(extract_date)\n",
    "\n",
    "df.drop(columns=['createDate', 'dateScanned', 'finishedDate', 'modifyDate', 'pointsAwardedDate', 'purchaseDate'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV file\n",
    "df.to_csv('D:/Resume/FetchInterview/receipts.json - Copy/receipts-Part1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
